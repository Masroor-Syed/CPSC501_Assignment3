{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cpsc501_Q2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucauyHiACtKQ",
        "colab_type": "text"
      },
      "source": [
        "Masroor Hussain Syed<br>\n",
        "30023900"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC8eIWt7C0aB",
        "colab_type": "text"
      },
      "source": [
        "Load tensorflow version 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1o4PRH6KJuJ",
        "colab_type": "code",
        "outputId": "32998d7c-4211-43b5-f6bd-6a56a5b015a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ughi_1E4dp",
        "colab_type": "text"
      },
      "source": [
        "Upload notMNIST.npz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4eVDT0IKKbh",
        "colab_type": "code",
        "outputId": "85703ab9-f80a-4ca9-e33e-3f07f7e0f7fa",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-365c2e9e-f60c-45e7-9178-275250f8d1e1\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-365c2e9e-f60c-45e7-9178-275250f8d1e1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving notMNIST.npz to notMNIST.npz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wJeHhxNDhxE",
        "colab_type": "text"
      },
      "source": [
        "# Deep Neural Net\n",
        "\n",
        "# Loading and Preprocessing \n",
        "\n",
        "1. I load the tensor library, we load the notMNIST data from my filesystem and it is split into the training set (x_train and y_train) and validation set (x_test and y_test). This is very important because we must test our model with data it hasn't seen before, otherwise our model will overfit on this data and might not perform well in real world.\n",
        "2. After loading the data, we normalize it to values between 0 and 1 because it makes training the neural network faster.\n",
        "\n",
        "# The Model\n",
        "1.   I used a sequential model for this problem because it was the standard and most neural network for this dataset use it.  \n",
        "2.   Model consists of an input layer with 784 neurons and 1 hidden layers with 256 neurons and an output layer with 10 neurons.\n",
        "3. I used the relu as the activation function for my hidden layer because it is less computationally  intense, converges faster because It doesn’t have the vanishing gradient problem and it doesn't activate for negative values so it is sparsely activated.\n",
        "4. The output layer using the softmax function as its activation function because it returns the probability distribution of the prediction for all \n",
        "possible categories, therefore it is great for classification networks.\n",
        "\n",
        "# Model Compilation and Training \n",
        "\n",
        "1.   I used the 'adam' optimizer for my model because it was providing the best result after experimenting with sgd and others and the loss function sparse_categorical_crossentropy was choosen for the same reason. To train the network I used 'accuracy' as metric because it is the standard practice for non-binary classifiers like ours.\n",
        "2.  I trained my model using 15 epocs because the training platoes here and the networks begins to overfit on this dataset.\n",
        "\n",
        "# Testing and saving \n",
        "1. After training the model, I test it by running the model on the the validation dataset and measure it accuracy. The model is able to predict 93.8% of the training data accuratly. \n",
        "2. I then save the trained model in the final notMNIST.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmlX83--KT6M",
        "colab_type": "code",
        "outputId": "35391d56-e80e-4062-e6e8-5c3d95983e8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"--Get data--\")\n",
        "with np.load(\"notMNIST.npz\", allow_pickle=True) as f:\n",
        "    x_train, y_train = f['x_train'], f['y_train']\n",
        "    x_test, y_test = f['x_test'], f['y_test']\n",
        "\n",
        "print(\"--Process data--\")\n",
        "print(len(y_train))\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        " \n",
        "print(\"--Make model--\")\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"--Fit model--\")\n",
        "model.fit(x_train, y_train, epochs=15, verbose=1)\n",
        "\n",
        "print(\"--Evaluate model--\")\n",
        "model_loss, model_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "print(f\"Model Loss:    {model_loss:.2f}\")\n",
        "print(f\"Model Accuray: {model_acc*100:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Get data--\n",
            "--Process data--\n",
            "60000\n",
            "--Make model--\n",
            "--Fit model--\n",
            "Train on 60000 samples\n",
            "Epoch 1/15\n",
            "60000/60000 [==============================] - 8s 128us/sample - loss: 0.5828 - accuracy: 0.8301\n",
            "Epoch 2/15\n",
            "60000/60000 [==============================] - 7s 109us/sample - loss: 0.4558 - accuracy: 0.8653\n",
            "Epoch 3/15\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.4038 - accuracy: 0.8795\n",
            "Epoch 4/15\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.3630 - accuracy: 0.8900\n",
            "Epoch 5/15\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.3306 - accuracy: 0.8993\n",
            "Epoch 6/15\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3013 - accuracy: 0.9086\n",
            "Epoch 7/15\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.2746 - accuracy: 0.9160\n",
            "Epoch 8/15\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2525 - accuracy: 0.9223\n",
            "Epoch 9/15\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2278 - accuracy: 0.9295\n",
            "Epoch 10/15\n",
            "60000/60000 [==============================] - 7s 110us/sample - loss: 0.2137 - accuracy: 0.9348\n",
            "Epoch 11/15\n",
            "60000/60000 [==============================] - 7s 113us/sample - loss: 0.1934 - accuracy: 0.9401\n",
            "Epoch 12/15\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1810 - accuracy: 0.9445\n",
            "Epoch 13/15\n",
            "60000/60000 [==============================] - 7s 114us/sample - loss: 0.1689 - accuracy: 0.9480\n",
            "Epoch 14/15\n",
            "60000/60000 [==============================] - 7s 115us/sample - loss: 0.1559 - accuracy: 0.9518\n",
            "Epoch 15/15\n",
            "60000/60000 [==============================] - 7s 112us/sample - loss: 0.1466 - accuracy: 0.9553\n",
            "--Evaluate model--\n",
            "10000/1 - 1s - loss: 0.1439 - accuracy: 0.9385\n",
            "Model Loss:    0.28\n",
            "Model Accuray: 93.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWL6XJe1GvN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm \"MNIST.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqOYMbbzEwUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save Model to notMNIST.h5\n",
        "model.save('notMNIST.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ZLaLRVEweP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('notMNIST.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqI9xdLWJYDc",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Net\n",
        "\n",
        "# Loading and Preprocessing \n",
        "\n",
        "1. The loading and preprocessing of the data is the name as the neural net above\n",
        "\n",
        "# The Model\n",
        "1. I used a sequential model for this problem because it was the standard and most neural networks for this dataset use it.\n",
        "\n",
        "2. The model consists of an input layer with 784 neurons and 2 convolutional layers and 1 hidden layer with 256 neurons and an output layer with 10 neurons.\n",
        "\n",
        "3. I used the 'relu' as the activation function for my layers because it is less computationally intense, converges faster because It doesn’t have the vanishing gradient problem and it doesn't activate for negative values so it is sparsely activated.\n",
        "\n",
        "4. The first convolutional layer consists of 32 3x3 filters, the uses relu as their activation function. The first convolutional layer consists of 64 3x3 filters and also uses relu as their activation function.\n",
        "\n",
        "5. After the first convolution layer, I use Maxlpool to compress the images such that these compressed images only highlight features in the images. I use the 2X2 grid for the max pool.\n",
        "\n",
        "6. I don't pool after the last CNN layer because it decreased my accuracy on the train and test data. Then the input is flattened as passed to the hidden layer with 256 neurons and then to the output layer with 10 neurons.\n",
        "\n",
        "7. The output layer using the softmax function as its activation function because it returns the probability distribution of the prediction for all possible categories, therefore it is great for classification networks.\n",
        "\n",
        "# Model Compilation and Training \n",
        "\n",
        "1. I used the 'Adam' optimizer for my model because it was providing the best result after experimenting with SGD and others and the loss function sparse_categorical_crossentropy was chosen for the same reason. To train the network I used 'accuracy' as metric because it is the standard practice for non-binary classifiers like ours.\n",
        "2. I trained my model using 20 epocs because the training plateaus here and the network begins to overfit on this dataset.\n",
        "\n",
        "# Testing and saving \n",
        "1. After training the model, I test it by running the model on the validation dataset and measure its accuracy. The model is able to predict 95.3% of the training data accurately.\n",
        "2. I then save the trained model in the final cnn_notMNIST.h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQZEbud4Qbv1",
        "colab_type": "code",
        "outputId": "74d110f5-4b58-448f-b4f0-dec4c1468e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 897
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"--Get data--\")\n",
        "with np.load(\"notMNIST.npz\", allow_pickle=True) as f:\n",
        "    x_train, y_train = f['x_train'], f['y_train']\n",
        "    x_test, y_test = f['x_test'], f['y_test']\n",
        "\n",
        "print(\"--Process data--\")\n",
        "print(len(y_train))\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "x_train = np.expand_dims(x_train, axis=3)\n",
        "x_test = np.expand_dims(x_test, axis=3)\n",
        " \n",
        "print(\"--Make model--\")\n",
        "model_cnn = tf.keras.models.Sequential([\n",
        "  # This is the first convolution                                      \n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28,1)),\n",
        "  tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "  # The second convolution\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  # Flatten the results to feed into a DNN\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(256, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model_cnn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"--Fit model--\")\n",
        "history = model_cnn.fit(x_train, y_train, epochs=20, verbose=1)\n",
        "\n",
        "print(\"--Evaluate model--\")\n",
        "model_loss, model_acc = model_cnn.evaluate(x_test,  y_test, verbose=2)\n",
        "print(f\"Model Loss:    {model_loss:.2f}\")\n",
        "print(f\"Model Accuray: {model_acc*100:.1f}%\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Get data--\n",
            "--Process data--\n",
            "60000\n",
            "--Make model--\n",
            "--Fit model--\n",
            "Train on 60000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 18s 293us/sample - loss: 0.4525 - accuracy: 0.8669\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 13s 222us/sample - loss: 0.3021 - accuracy: 0.9084\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 13s 222us/sample - loss: 0.2198 - accuracy: 0.9312\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 13s 222us/sample - loss: 0.1413 - accuracy: 0.9567\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 13s 221us/sample - loss: 0.0859 - accuracy: 0.9752\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0577 - accuracy: 0.9837\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 13s 224us/sample - loss: 0.0474 - accuracy: 0.9879\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0403 - accuracy: 0.9893\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0360 - accuracy: 0.9901\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0314 - accuracy: 0.9919\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0281 - accuracy: 0.9925\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 14s 226us/sample - loss: 0.0279 - accuracy: 0.9924\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0253 - accuracy: 0.9937\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0220 - accuracy: 0.9941\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0231 - accuracy: 0.9937\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0218 - accuracy: 0.9943\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0217 - accuracy: 0.9942\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0179 - accuracy: 0.9952\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0211 - accuracy: 0.9942\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 13s 220us/sample - loss: 0.0179 - accuracy: 0.9948\n",
            "--Evaluate model--\n",
            "10000/1 - 1s - loss: 0.5578 - accuracy: 0.9534\n",
            "Model Loss:    0.38\n",
            "Model Accuray: 95.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSmKsA6BWFwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save Model to cnn_notMNIST.h5\n",
        "model_cnn.save('cnn_notMNIST.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62JpKq4DWVCK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('cnn_notMNIST.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKbUSF1SW5m1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm \"cnn_notMNIST.h5\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}